---
title: "America Runs on Data - Dunkin' EDA Project"
author: "Evan Cypher"
date: '2021-01-29'
output: html_document
lastmod: '2020-07-10T13:49:49-04:00'
slug: test
thumbnail: https://raw.githubusercontent.com/ecypher/ecypher.github.io/master/images/Dunkin_Resized.png
type: post
w3codecolor: no
---

```{r packages, echo = FALSE, message = FALSE}
# Packages
library(dplyr)
```

### Overview

I worked at Dunkin' Donuts for nearly five years - from my first job in high school at age 17 to graduating college at age 22. Dunkin' provided my first glimpse at the working world, introduced me to great friends, helped pay my college tuition, and fueled an unyielding caffeine addiction.

Even after leaving Dunkin' in pursuits of becoming a data scientist, I'm still a loyal customer and love keeping tabs on what's new with the brand.
So for my first blog post, I want to explore what data-driven insights might be gathered about Dunkin' using only publicly available data (i.e. web scraping, API's, and financial documentation).

### How do I find my Dunkin' Data?

Dunkin' Donuts has a Mobile App</a> for on-the-go ordering that lists all available stores in a user's area based on zip code. My hope was that I might be able to connect to the web API underpinning this app and collect data on store locations in the United States.

Fortunately this was the case and I wasn't even the first person to try this out! I came across a blog post titled <a href = "https://www.isaacslavitt.com/posts/dunkin-donuts-data-analysis/" target = "_blank">"Analyzing Dunkin' Donuts' business with scraped data"</a> by Isaac Slavitt (Jan 8, 2014). Seven years ago, Issac had essentially the same goal as mine. He collected data from the MAPQuest API that underpins Dunkin's store locator, explored the data with Python, and visualized some interesting results.

I'm going to mirror Issac's approach, but my post utilizes the R programming language, asks several different questions, and has the luxury of seeing how things have changed in terms of Dunkin's data reporting since 2014.

### Connecting to the MapQuest API

The <a href = "https://developer.mapquest.com/documentation/search-api/v2/" target = "_blank">MapQuest API</a> provides up to 4000 records of location data and auxiliary information in a single GET request. Data can be in either JSON or XML format based on the "outputFormat" parameter. 

All U.S. Dunkin' store records were combined into a single dataframe by looping a series of eight GET requests together based on different bounding boxes. Each bounding box was optimized to corresponded with roughly 4000 records to complete the dataset with the fewest number of iterations. The httr, jsonlite, and dplyr packages were all used in the data wrangling process and can be viewed by clicking on the "Code" button or visiting my GitHub repo.

<button type="button" class="collapsible">Code</button>
<div class="content">

```{r, eval = FALSE, echo = TRUE}
# Required Packages
library(httr)       # Used to write GET requests
library(jsonlite)   # Used to manipulate JSON data
library(rlist)      # A Toolbox for Non-Tabular Data Manipulation
library(dplyr)      # Dataframe manipulation package from tidyvesre
library(openintro)  # Convert Abbr to State Names
library(micromapST) # Used to create linked micromaps

# Original URL
"https://www.mapquestapi.com/search/v2/radius?callback=jQuery34104664634028664918_1592271610628&key=Gmjtd%7Clu6t2luan5%252C72%253Do5-larsq&origin=22033&units=m&maxMatches=100&radius=100&hostedData=mqap.33454_DunkinDonuts&ambiguities=ignore&_=1592271610632"

# Bounding Box Coordinates that capture the entire
# United States (including Alaska and Hawaii)
bb_set <- c("24.00,-85.00,49.00,-125.00",
            "24.00,-85.00,49.50,-80.00",
            "24.00,-80.00,49.50,-76.25",
            "24.00,-76.25,49.50,-73.00",
            "24.00,-73.00,49.50,-69.50",
            "24.00,-69.50,49.50,-66.00",
            "50.70,-169.30,71.70,-140.00",
            "15.00,-179.00,29.00,-154.00")

# Create empty dataframe to be populated by "for loop"
Dunkin_DT <- data_frame()

##-------------------------------------------------------------------##
##  Loop connects to MapQuest API,                                   ##
##  gets JSON containing data on Dunkin' stores in the bounding box, ##
##  and selects relevant variables (columns)                         ##
##-------------------------------------------------------------------## 

for (bb in bb_set){
    
# List of Key-Value pairs for Query Params
query_params <- list(key = "38aDNOGAHfyHqf9A7AtARNZuXbjGYGI5",
                     boundingBox = bb,
                     units = "m",
                     maxMatches = "4000", # Limit for Parameter is 4000
                     hostedData = "mqap.33454_DunkinDonuts",
                     outFormat = "json",
                     ambiguities = "ignore")

# GET request utilizing Map Quest API
get_result <- GET(url = "https://www.mapquestapi.com/search/v2/rectangle?",
                  query = query_params,
                  config = user_agent("contact.data.antics@gmail.com - data is being collected for non-commercial uses ONLY"))

# Verify that contents are JSON
http_type(get_result)

# Transform JSON into R Dataframe
pageview <- fromJSON(content(get_result, as = "text"),
                         simplifyDataFrame = TRUE)$searchResults$fields

# Select only the variables (columns) that might interest me
select_cols <- pageview %>% 
                select(recordid, address, address2, city,
                       state, postal, county, country,
                       phonenumber, lat, lng, sun_hours, mon_hours,
                       tue_hours, wed_hours, thu_hours, fri_hours,
                       sat_hours, sitetype, pos_type, co_brander_cd,
                       operation_status_cd, dma_cd, close_reason_cd,
                       otg_menu_opt, combostore, beverageonly,
                       curbside, drivein, wireless, mobile,
                       mobile_bypass_lane, dunkincardenabled,
                       loyalty, adv_ord, high_vol_brewer,
                       next_gen_store, catering_flag, walkin_flag,
                       kosher, dt_auto_fire, turbooven, k_cup,
                       almond, tender_agnostic_enabled)

# Populate Observations from current bounding box
Dunkin_DT <- rbind(Dunkin_DT, select_cols)

}

# Eliminate Duplicate rows in cases where bounding boxes slightly overlap
Dunkin_DT_No_Dups <- Dunkin_DT %>% 
                        distinct(recordid, .keep_all = TRUE)

# Quickly Check State Rankings
Ranking <- Dunkin_DT_No_Dups %>% 
            group_by(state) %>% 
            count() %>% 
            arrange(desc(n))

# Date Saved: 2020-06-26
saveRDS(Dunkin_DT_No_Dups, file = "Dunkin_Donuts.rds")

```

</div>

```{r load_query, echo = FALSE, message = FALSE}
# Load Dunkin_Donuts.rds
Dunkin_DT <- readRDS(url("https://github.com/ecypher/ecypher.github.io/raw/master/content/english/ref%20files/Dunkin_Donuts_2021.rds"))

```

<br>

### What does the data look like?

At first glimpse, we can see that there are 9,238 Dunkin' stores and each record has 45 fun-filled variables to explore. Every variable has a class of "character" except for *<i>recordid</i>* which is "integer" and the coordinates *<i>lat</i>* and *<i>lng</i>* are both "double". 

Columns 2 through 11 each contain information with varying levels of geographic granularity (ex. *<i>address</i>*, *<i>city</i>*, *<i>state</i>*, *<i>county</i>*, etc.)
```{r check_dim, echo = TRUE}

# Look at Data Structure with glimpse()
 glimpse(Dunkin_DT)

```


### Data Exploration

- Check for null / missing values
- Show dimensions dim()
- List Different Variables
- Talking about some of the more interesting variables
- Boxplots / Scatter Plots / Contingency Tables / Histograms

### Introductions

This page exists purely for testing purposes. I'm typing in pure nonsense right now because I really, really want to increase the total word length for this article.This page exists purely for testing purposes. I'm typing in pure nonsense right now because I really, really want to increase the total word length for this article. This page exists purely for testing purposes. I'm typing in pure nonsense right now because I really, really want to increase the total word length for this article.

### TL;DR

### Collecting Data


### Dendo Test

```{r  out.width = "30%", echo = FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/ecypher/ecypher.github.io/master/images/Dunkin_Dendo_D3.png") 
```


### Linked Micromap Test

<center>![](https://raw.githubusercontent.com/ecypher/ecypher.github.io/master/images/Dunkin_Linked_MicromapST.png)</center>


### R Shiny Marker Map

<iframe src=" https://data-antics.shinyapps.io/DunkinMapApp/" width="100%" frameborder="no" scrolling="no" style="width: 100%; height: 500px;"></iframe>

### R Shiny Leaflet Choropleth Map

<iframe src = "https://data-antics.shinyapps.io/Dunkin_Choropleth/" width="100%" frameborder="no" scrolling="no" style="width: 100%; height: 600px;"></iframe>

### Another Section

I love Dunkin' Donuts

## Legality Note

This is a personal project made for non-commercial uses ONLY. This project will not be used to generate any promotional or monetary value for me, the creator, or the user.

<p style = "font-size:12px">
<u>Please Note:</u><br>
I use the terms <i>Dunkin'</i>, <i> Dunkin' Donuts</i>, and <i>Dunkin' Brands</i> interchangeably although there are actually differences between the three. When I first worked at the franchise, the stores were called <i> Dunkin' Donuts</i>. In September 2018, however, <a href = "https://www.delish.com/food-news/a23494352/dunkin-donuts-ceo-reasons-for-name-change/" target = "_blank">the name was shortened to just Dunkin'</a> for brand imaging. <i>Dunkin' Brands</i> is the American restaurant holding company that runs both <i>Dunkin Donuts</i> and Baskin-Robbins. More recently in October 2020, <a href = "https://stories.inspirebrands.com/inspire-completes-acquisition-dunkin-donuts-baskin-robbins/" target = "_blank">Dunkin' Brands was acquired by privately-owned Inspire Brands, Inc</a> for $11.3 billion.
</p>
